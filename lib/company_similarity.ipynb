{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Pinecone index with a company description + Twitter Bio\n",
    "We will use the index as the backend database for our search API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU sentence-transformers pinecone-client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Sentence Transformer model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test a few different transformer models\n",
    "We recommend focusing on cosine similarity but feel free to try a couple with examples below and check the similarity score you get to pick the right model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: tensor([[0.4602]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "# encoding = 'msmarco-distilbert-base-v4' # Similarity: tensor([[0.2574]])\n",
    "encoding = 'bert-base-nli-mean-tokens' # Similarity: tensor([[0.4602]])\n",
    "# encoding = 'paraphrase-multilingual-mpnet-base-v2' # Similarity: tensor([[0.4039]])\n",
    "# encoding = 'all-MiniLM-L6-v2' # Similarity: tensor([[0.3404]])\n",
    "# encoding = 'all-mpnet-base-v2' # Similarity: tensor([[0.4056]])\n",
    "# encoding = 'all-roberta-large-v1' # Similarity: tensor([[0.3546]])\n",
    "model = SentenceTransformer(encoding) \n",
    "\n",
    "query_embedding = model.encode('Account-Based Marketing')\n",
    "passage_embedding = model.encode('6sense is an AI powered account based orchestration platform that provides predictive intelligence to help B2B companies reach their ideal customers at the right time With 6senses solution marketers can identify and prioritize accounts that are most')\n",
    "\n",
    "print(\"Similarity:\", util.cos_sim(query_embedding, passage_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode a set of company descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98840\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10x</td>\n",
       "      <td>Your Data Is Your Busness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Funsales</td>\n",
       "      <td>Conhea todos os nossos apps Criador de Promoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unitedprofile</td>\n",
       "      <td>Nordens kraftfullaste webbportal fr profil yrk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neurons-IT</td>\n",
       "      <td>Neuronsit  is an professional website designin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Church Base</td>\n",
       "      <td>Church base offers a complete church engagemen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name                                        description\n",
       "0            10x                         Your Data Is Your Busness \n",
       "2       Funsales  Conhea todos os nossos apps Criador de Promoes...\n",
       "3  Unitedprofile  Nordens kraftfullaste webbportal fr profil yrk...\n",
       "4     Neurons-IT  Neuronsit  is an professional website designin...\n",
       "5    Church Base  Church base offers a complete church engagemen..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data from the csv file\n",
    "import pandas as pd\n",
    "df_all = pd.read_csv('../data/tech_companies.csv')\n",
    "\n",
    "\n",
    "# replace NaN with empty string\n",
    "df_all = df_all.fillna('')\n",
    "\n",
    "# remove the rows with no name\n",
    "df_all = df_all[df_all['name'] != '']\n",
    "\n",
    "# remove the rows with no description and no twitter__bio\n",
    "df_all = df_all[(df_all['description'] != '') | (df_all['twitter__bio'] != '')]\n",
    "\n",
    "# get the number of records in the dataframe\n",
    "print(len(df_all))\n",
    "\n",
    "# put the first 20000 companies into a dataframe and only keep the name and description columns\n",
    "# combine the description and twitter__bio column into a new column called description\n",
    "df = df_all[:100000][['name', 'description', 'twitter__bio']]\n",
    "df['description'] = df['description'] + ' ' + df['twitter__bio']\n",
    "df = df[['name', 'description']]\n",
    "df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push embeddings to Pinecone to be accessed by our endpoint in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our pinecone_api_key from the environment variable\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Set API credentials as variables => Please make sure you have a .env file with the following variables\n",
    "PINECONE_API_KEY = os.environ[\"PINECONE_API_KEY\"]\n",
    "PINECONE_ENV = os.environ[\"PINECONE_ENV\"]\n",
    "\n",
    "# connect to our pinecone instance\n",
    "from pinecone import init\n",
    "init(\n",
    "    api_key=PINECONE_API_KEY, \n",
    "    environment=PINECONE_ENV\n",
    ")\n",
    "\n",
    "# Create a pincone index\n",
    "# if the index already exists, delete it and create a new one\n",
    "from pinecone import create_index, list_indexes, Index, delete_index\n",
    "if \"companies\" not in list_indexes():\n",
    "    create_index(name=\"companies\", metric=\"cosine\", shards=1, dimension=768)\n",
    "else:\n",
    "    delete_index(\"companies\")\n",
    "    create_index(name=\"companies\", metric=\"cosine\", shards=1, dimension=768)\n",
    "\n",
    "# list_indexes()\n",
    "index = Index(\"companies\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index the Vectors\n",
    "Since we're likely going to run this on decently big batches, we want to process in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 773/773 [7:30:33<00:00, 34.97s/it]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.1,\n",
       " 'namespaces': {'': {'vector_count': 98840}},\n",
       " 'total_vector_count': 98840}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# we will use batches of 128\n",
    "batch_size = 128\n",
    "\n",
    "for i in tqdm(range(0, len(df), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(df))\n",
    "    # extract batch\n",
    "    batch = df.iloc[i:i_end]\n",
    "    # generate embeddings for batch\n",
    "    emb = model.encode(batch['description'].tolist()).tolist()\n",
    "    # get metadata\n",
    "    meta = batch.to_dict(orient='records')\n",
    "    # create unique IDs\n",
    "    ids = [f\"{idx}\" for idx in range(i, i_end)]\n",
    "    # add all to upsert list\n",
    "    to_upsert = list(zip(ids, emb, meta))\n",
    "    # upsert/insert these records to pinecone\n",
    "    _ = index.upsert(vectors=to_upsert)\n",
    "\n",
    "# check that we have all vectors in index\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the index by querying it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '69334',\n",
       "              'metadata': {'description': 'A bestinclass construction platform '\n",
       "                                          'that intelligently collates your '\n",
       "                                          'documentation process to ease of '\n",
       "                                          'use From BQ etendering and project '\n",
       "                                          'management BuildSpace is a '\n",
       "                                          'web-enabled total solution built to '\n",
       "                                          'cater a variety of functions '\n",
       "                                          'required in Building and '\n",
       "                                          'Construction Industry.',\n",
       "                           'name': 'BuildSpace'},\n",
       "              'score': 0.915593803,\n",
       "              'values': []},\n",
       "             {'id': '91575',\n",
       "              'metadata': {'description': 'We help convert your tech ideas '\n",
       "                                          'into reality by using our tech '\n",
       "                                          'skills spanning various domains of '\n",
       "                                          'web development web design and much '\n",
       "                                          'more ',\n",
       "                           'name': 'FabNinjas Pvt'},\n",
       "              'score': 0.907824814,\n",
       "              'values': []},\n",
       "             {'id': '8429',\n",
       "              'metadata': {'description': 'Bespoke web software development '\n",
       "                                          'Web IoT CRM and Reporting Bring '\n",
       "                                          'your data to life with our custom '\n",
       "                                          'portals ',\n",
       "                           'name': 'Exe Squared'},\n",
       "              'score': 0.906255126,\n",
       "              'values': []}],\n",
       " 'namespace': ''}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"platform is a web-based designing, prototyping, and collaboration tool, enabling developers, product managers, and marketers to simplify design workflows\"\n",
    "\n",
    "# create the query vector\n",
    "xq = model.encode(query).tolist()\n",
    "\n",
    "# now query\n",
    "xc = index.query(xq, top_k=3, include_metadata=True)\n",
    "xc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
