{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Test with a company description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU sentence-transformers pinecone-client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Sentence Transformer model\n",
    "you could also use: `all-mpnet-base-v2` or `all-roberta-large-v1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode a set of company descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10x</td>\n",
       "      <td>Your Data Is Your Busness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>RandomKeygen is a free mobilefriendly tool tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Funsales</td>\n",
       "      <td>Conhea todos os nossos apps Criador de Promoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unitedprofile</td>\n",
       "      <td>Nordens kraftfullaste webbportal fr profil yrk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neurons-IT</td>\n",
       "      <td>Neuronsit  is an professional website designin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Church Base</td>\n",
       "      <td>Church base offers a complete church engagemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pollicy</td>\n",
       "      <td>Pollicy is a feminist collective of technologi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Doshaheen Solutions Pvt.</td>\n",
       "      <td>Doshaheen Solutions Pvt Ltd DSPL is a boutique...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MevoFit</td>\n",
       "      <td>Professional AllinOne Platform for Fitness Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>teamblau</td>\n",
       "      <td>Lass dich von unseren Referenzen inspirieren E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name                                        description\n",
       "0                       10x                          Your Data Is Your Busness\n",
       "1                            RandomKeygen is a free mobilefriendly tool tha...\n",
       "2                  Funsales  Conhea todos os nossos apps Criador de Promoes...\n",
       "3             Unitedprofile  Nordens kraftfullaste webbportal fr profil yrk...\n",
       "4                Neurons-IT  Neuronsit  is an professional website designin...\n",
       "5               Church Base  Church base offers a complete church engagemen...\n",
       "6                   Pollicy  Pollicy is a feminist collective of technologi...\n",
       "7  Doshaheen Solutions Pvt.  Doshaheen Solutions Pvt Ltd DSPL is a boutique...\n",
       "8                   MevoFit  Professional AllinOne Platform for Fitness Pro...\n",
       "9                  teamblau  Lass dich von unseren Referenzen inspirieren E..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentences = [\n",
    "#     \"Madkudu is a predictive lead scoring platform that leverages machine learning to help B2B companies identify their best leads and drive revenue growth By analyzing data from marketing and sales systems Madkudu provides teams with actionable insights\",\n",
    "#         \"Terminus is a leading account based marketing ABM platform enabling businesses to engage with target accounts and deliver tailored experiences It offers a suite of solutions including advertising web personalization CRM integration and analytic\", \n",
    "#         \"Endgameio is a cybersecurity company that offers nextgen endpoint protection and threat intelligence to protect enterprise networks from advanced threats Its products include a cloudnative endpoint detection and response platform malware analysis\" , \n",
    "#         \"6sense is an AI powered accoun tbased orchestration platform that provides predictive intelligence to help B2B companies reach their ideal customers at the right time With 6senses solution marketers can identify and prioritize accounts that are most\"\n",
    "#         ]\n",
    "\n",
    "# load the data from the csv file\n",
    "import pandas as pd\n",
    "df_all = pd.read_csv('../data/tech_companies.csv')\n",
    "\n",
    "\n",
    "# replace NaN with empty string\n",
    "df_all = df_all.fillna('')\n",
    "\n",
    "# put the first 1000 companies into a dataframe and only keep the name and description columns\n",
    "df = df_all[['name', 'description']][:1000]\n",
    "df.head(10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push embeddings to Pinecone to be accessed by our endpoint in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our pinecone_api_key from the environment variable\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Set API credentials as variables => Please make sure you have a .env file with the following variables\n",
    "PINECONE_API_KEY = os.environ[\"PINECONE_API_KEY\"]\n",
    "PINECONE_ENV = os.environ[\"PINECONE_ENV\"]\n",
    "\n",
    "# connect to our pinecone instance\n",
    "from pinecone import init\n",
    "init(\n",
    "    api_key=PINECONE_API_KEY, \n",
    "    environment=PINECONE_ENV\n",
    ")\n",
    "\n",
    "# Create a pincone index\n",
    "from pinecone import create_index, list_indexes, Index\n",
    "if \"companies\" not in list_indexes():\n",
    "    create_index(name=\"companies\", metric=\"cosine\", shards=1, dimension=768)\n",
    "\n",
    "# list_indexes()\n",
    "\n",
    "index = Index(\"companies\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index the Vectors\n",
    "Since we're likely going to run this on decently big batches, we want to process in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:52<00:00,  7.03s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 1000}},\n",
       " 'total_vector_count': 1000}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# we will use batches of 64\n",
    "batch_size = 64\n",
    "\n",
    "for i in tqdm(range(0, len(df), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(df))\n",
    "    # extract batch\n",
    "    batch = df.iloc[i:i_end]\n",
    "    # generate embeddings for batch\n",
    "    emb = model.encode(batch['description'].tolist()).tolist()\n",
    "    # get metadata\n",
    "    meta = batch.to_dict(orient='records')\n",
    "    # create unique IDs\n",
    "    ids = [f\"{idx}\" for idx in range(i, i_end)]\n",
    "    # add all to upsert list\n",
    "    to_upsert = list(zip(ids, emb, meta))\n",
    "    # upsert/insert these records to pinecone\n",
    "    _ = index.upsert(vectors=to_upsert)\n",
    "\n",
    "# check that we have all vectors in index\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our pinecode index to find the knn companies based the description of a new company\n",
    "# calculate the similarities between a new description and the embeddings in our index\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Similarities matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>sim = np.zeros((<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(sentences), <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(sentences)))                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(sentences)):                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 7 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>sim[i:,i] = cos_sim(embeddings[i], embeddings[i:])                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span>sim.shape                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m7\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0msim = np.zeros((\u001b[96mlen\u001b[0m(sentences), \u001b[96mlen\u001b[0m(sentences)))                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[94mfor\u001b[0m i \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(\u001b[96mlen\u001b[0m(sentences)):                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 7 \u001b[2m│   \u001b[0msim[i:,i] = cos_sim(embeddings[i], embeddings[i:])                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0msim.shape                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "sim = np.zeros((len(sentences), len(sentences)))\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    sim[i:,i] = cos_sim(embeddings[i], embeddings[i:])\n",
    "\n",
    "sim.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get me the similarity scores between 2 companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75957190990448"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# given 2 company names, return the similarity score\n",
    "def get_similarity_score(company1, company2):\n",
    "    index1 = df[df['name'] == company1].index[0]\n",
    "    index2 = df[df['name'] == company2].index[0]\n",
    "    # if one of the 2 companies is not in the list, return 0\n",
    "    if index1 == -1 or index2 == -1:\n",
    "        return 0\n",
    "    return sim[index1, index2]\n",
    "\n",
    "get_similarity_score('AccountPal', 'Ubiquity NZ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For a given index return its sentence and return the k-nn sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AccountPal', 'Account Centric Sales and Marketing on Salesforce', 1.0),\n",
       " ('54 North Limited',\n",
       "  'Revenue Management Solutions for Retailers',\n",
       "  0.8695738911628723),\n",
       " ('Bridgeway Solutions',\n",
       "  'Comprehensive ID and access management software and hardware solution Sales integration service  support',\n",
       "  0.8162314891815186),\n",
       " ('8C Partners', 'Marketing Consulting Finance Data', 0.8125531077384949),\n",
       " ('Aynsoft - India',\n",
       "  'Automate the workflow process of Lead management Sales pipeline Marketing and Customer acquisition giving companies the ability to track performance and',\n",
       "  0.8023368120193481)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for a given company, find the top 5 most similar companies\n",
    "def find_similar_companies(company_name, sim, sentences, top_n=5):\n",
    "    # if the company is not in the list, return empty list\n",
    "    if company_name not in df['name'].tolist():\n",
    "        return []\n",
    "    sentence = df[df['name'] == company_name]['description'].tolist()[0]\n",
    "    idx = sentences.index(sentence)\n",
    "    top_n_idx = np.argsort(sim[idx,:])[-top_n:][::-1]\n",
    "    res = []\n",
    "    for i in top_n_idx:\n",
    "        if sim[idx,i] >= 0.3:\n",
    "            res.append((df['name'][i],sentences[i], sim[idx,i]))\n",
    "    return res\n",
    "\n",
    "find_similar_companies('AccountPal', sim, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AccountPal',\n",
       "  'Account Centric Sales and Marketing on Salesforce',\n",
       "  0.8345026969909668),\n",
       " ('Ubiquity NZ', 'Customer Engagement Marketing Software', 0.7729628086090088),\n",
       " ('A Guy I Know',\n",
       "  'Managed IT Fulfillment Administration and Infrastructure Services',\n",
       "  0.7712785601615906),\n",
       " ('Apāto',\n",
       "  'Decentralised realestate ownership through distributed ledger technology',\n",
       "  0.7684563398361206),\n",
       " ('54 North Limited',\n",
       "  'Revenue Management Solutions for Retailers',\n",
       "  0.7599304914474487)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for a company based on a sentence using the sim matrix\n",
    "def search_company(sentence, sim, sentences, top_n=5):\n",
    "    sentence_embedding = model.encode([sentence])\n",
    "    sim_score = np.zeros(len(sentences))\n",
    "    for i in range(len(sentences)):\n",
    "        sim_score[i] = cos_sim(sentence_embedding, embeddings[i])\n",
    "    top_n_idx = np.argsort(sim_score)[-top_n:][::-1]\n",
    "    res = []\n",
    "    for i in top_n_idx:\n",
    "        if sim_score[i] >= 0.3:\n",
    "            res.append((df['name'][i],sentences[i], sim_score[i]))\n",
    "    return res\n",
    "\n",
    "search_company('account based marketing', sim, sentences)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
