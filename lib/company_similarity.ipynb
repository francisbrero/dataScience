{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Pinecone index with a company description + Twitter Bio\n",
    "We will use the index as the backend database for our search API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -qU sentence-transformers pinecone-client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Sentence Transformer model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test a few different transformer models\n",
    "We recommend focusing on cosine similarity but feel free to try a couple with examples below and check the similarity score you get to pick the right model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "# encoding = 'msmarco-distilbert-base-v4' # Similarity: tensor([[0.2574]])\n",
    "encoding = 'bert-base-nli-mean-tokens' # Similarity: tensor([[0.4602]])\n",
    "# encoding = 'paraphrase-multilingual-mpnet-base-v2' # Similarity: tensor([[0.4039]])\n",
    "# encoding = 'all-MiniLM-L6-v2' # Similarity: tensor([[0.3404]])\n",
    "# encoding = 'all-mpnet-base-v2' # Similarity: tensor([[0.4056]])\n",
    "# encoding = 'all-roberta-large-v1' # Similarity: tensor([[0.3546]])\n",
    "model = SentenceTransformer(encoding) \n",
    "\n",
    "query_embedding = model.encode('Account-Based Marketing')\n",
    "passage_embedding = model.encode('6sense is an AI powered account based orchestration platform that provides predictive intelligence to help B2B companies reach their ideal customers at the right time With 6senses solution marketers can identify and prioritize accounts that are most')\n",
    "\n",
    "print(\"Similarity:\", util.cos_sim(query_embedding, passage_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode a set of company descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from the csv file\n",
    "import pandas as pd\n",
    "df_all = pd.read_csv('../data/tech_companies.csv')\n",
    "\n",
    "\n",
    "# replace NaN with empty string\n",
    "df_all = df_all.fillna('')\n",
    "\n",
    "# remove the rows with no name\n",
    "df_all = df_all[df_all['name'] != '']\n",
    "\n",
    "# remove the rows with no description and no twitter__bio\n",
    "df_all = df_all[(df_all['description'] != '') | (df_all['twitter__bio'] != '')]\n",
    "\n",
    "# get the number of records in the dataframe\n",
    "print(len(df_all))\n",
    "\n",
    "# put the first 20000 companies into a dataframe and only keep the name and description columns\n",
    "# combine the description and twitter__bio column into a new column called description\n",
    "df = df_all[:100000][['name', 'description', 'twitter__bio']]\n",
    "df['description'] = df['description'] + ' ' + df['twitter__bio']\n",
    "df = df[['name', 'description']]\n",
    "df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push embeddings to Pinecone to be accessed by our endpoint in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our pinecone_api_key from the environment variable\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Set API credentials as variables => Please make sure you have a .env file with the following variables\n",
    "PINECONE_API_KEY = os.environ[\"PINECONE_API_KEY\"]\n",
    "PINECONE_ENV = os.environ[\"PINECONE_ENV\"]\n",
    "\n",
    "# connect to our pinecone instance\n",
    "from pinecone import init\n",
    "init(\n",
    "    api_key=PINECONE_API_KEY, \n",
    "    environment=PINECONE_ENV\n",
    ")\n",
    "\n",
    "# Create a pincone index\n",
    "# if the index already exists, delete it and create a new one\n",
    "from pinecone import create_index, list_indexes, Index, delete_index\n",
    "if \"companies\" not in list_indexes():\n",
    "    create_index(name=\"companies\", metric=\"cosine\", shards=1, dimension=768)\n",
    "else:\n",
    "    delete_index(\"companies\")\n",
    "    create_index(name=\"companies\", metric=\"cosine\", shards=1, dimension=768)\n",
    "\n",
    "# list_indexes()\n",
    "index = Index(\"companies\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index the Vectors\n",
    "Since we're likely going to run this on decently big batches, we want to process in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# we will use batches of 128\n",
    "batch_size = 128\n",
    "\n",
    "for i in tqdm(range(0, len(df), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(df))\n",
    "    # extract batch\n",
    "    batch = df.iloc[i:i_end]\n",
    "    # generate embeddings for batch\n",
    "    emb = model.encode(batch['description'].tolist()).tolist()\n",
    "    # get metadata\n",
    "    meta = batch.to_dict(orient='records')\n",
    "    # create unique IDs\n",
    "    ids = [f\"{idx}\" for idx in range(i, i_end)]\n",
    "    # add all to upsert list\n",
    "    to_upsert = list(zip(ids, emb, meta))\n",
    "    # upsert/insert these records to pinecone\n",
    "    _ = index.upsert(vectors=to_upsert)\n",
    "\n",
    "# check that we have all vectors in index\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the index by querying it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"platform is a web-based designing, prototyping, and collaboration tool, enabling developers, product managers, and marketers to simplify design workflows\"\n",
    "\n",
    "# create the query vector\n",
    "xq = model.encode(query).tolist()\n",
    "\n",
    "# now query\n",
    "xc = index.query(xq, top_k=3, include_metadata=True)\n",
    "xc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
