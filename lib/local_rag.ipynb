{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"source":["# Introduction\n","\n","<img src=\"https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F769452%2Fb18d0513200d426e556b2b7b7c825981%2FRAG.png?generation=1695504022336680&alt=media\"></img>\n","\n","## Objective\n","\n","Use Llama 2.0, Langchain and ChromaDB to create a Retrieval Augmented Generation (RAG) system. This will allow us to ask questions about our documents (that were not included in the training data), without fine-tunning the Large Language Model (LLM).\n","When using RAG, if you are given a question, you first do a retrieval step to fetch any relevant documents from a special database, a vector database where these documents were indexed. \n","\n","## Definitions\n","\n","* LLM - Large Language Model  \n","* Llama 2.0 - LLM from Meta \n","* Langchain - a framework designed to simplify the creation of applications using LLMs\n","* Vector database - a database that organizes data through high-dimmensional vectors  \n","* ChromaDB - vector database  \n","* RAG - Retrieval Augmented Generation (see below more details about RAGs)\n","\n","## Model details\n","\n","* **Model**: Llama 2  \n","* **Variation**: 7b-chat-hf  (7b: 7B dimm. hf: HuggingFace build)\n","* **Version**: V1  \n","* **Framework**: PyTorch  \n","\n","LlaMA 2 model is pretrained and fine-tuned with 2 Trillion tokens and 7 to 70 Billion parameters which makes it one of the powerful open source models. It is a highly improvement over LlaMA 1 model.\n","\n","\n","## What is a Retrieval Augmented Generation (RAG) system?\n","\n","Large Language Models (LLMs) has proven their ability to understand context and provide accurate answers to various NLP tasks, including summarization, Q&A, when prompted. While being able to provide very good answers to questions about information that they were trained with, they tend to hallucinate when the topic is about information that they do \"not know\", i.e. was not included in their training data. Retrieval Augmented Generation combines external resources with LLMs. The main two components of a RAG are therefore a retriever and a generator.  \n"," \n","The retriever part can be described as a system that is able to encode our data so that can be easily retrieved the relevant parts of it upon queriying it. The encoding is done using text embeddings, i.e. a model trained to create a vector representation of the information. The best option for implementing a retriever is a vector database. As vector database, there are multiple options, both open source or commercial products. Few examples are ChromaDB, Mevius, FAISS, Pinecone, Weaviate. Our option in this Notebook will be a local instance of ChromaDB (persistent).\n","\n","For the generator part, the obvious option is a LLM. In this Notebook we will use a quantized LLaMA v2 model, from the Kaggle Models collection.  \n","\n","The orchestration of the retriever and generator will be done using Langchain. A specialized function from Langchain allows us to create the receiver-generator in one line of code."]},{"cell_type":"markdown","metadata":{},"source":["# Installations, imports, utils"]},{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-09-24T11:27:16.337009Z","iopub.status.busy":"2023-09-24T11:27:16.336361Z","iopub.status.idle":"2023-09-24T11:30:52.668755Z","shell.execute_reply":"2023-09-24T11:30:52.667418Z","shell.execute_reply.started":"2023-09-24T11:27:16.336972Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Skipping /usr/local/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping /usr/local/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.11/site-packages (4.34.0)\n","Collecting accelerate\n","  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/d9/92/2d3aecf9f4a192968035880be3e2fc8b48d541c7128f7c936f430d6f96da/accelerate-0.23.0-py3-none-any.whl.metadata\n","  Downloading accelerate-0.23.0-py3-none-any.whl.metadata (18 kB)\n","Collecting einops\n","  Obtaining dependency information for einops from https://files.pythonhosted.org/packages/29/0b/2d1c0ebfd092e25935b86509a9a817159212d82aa43d7fb07eca4eeff2c2/einops-0.7.0-py3-none-any.whl.metadata\n","  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: langchain in /usr/local/lib/python3.11/site-packages (0.0.310)\n","Collecting langchain\n","  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/1f/46/d82192ebc8d1f0e42b03b5c8a078737fba9fe8ec416722f5865ed9424d49/langchain-0.0.311-py3-none-any.whl.metadata\n","  Downloading langchain-0.0.311-py3-none-any.whl.metadata (15 kB)\n","Collecting xformers\n","  Downloading xformers-0.0.22.tar.gz (3.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting bitsandbytes\n","  Obtaining dependency information for bitsandbytes from https://files.pythonhosted.org/packages/1e/2c/af22cd797fc368a9f098ed03015730e6568b884fe67f9940793d944a4b7b/bitsandbytes-0.41.1-py3-none-any.whl.metadata\n","  Downloading bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\n","Requirement already satisfied: chromadb in /usr/local/lib/python3.11/site-packages (0.4.13)\n","Collecting chromadb\n","  Obtaining dependency information for chromadb from https://files.pythonhosted.org/packages/3c/ff/ac74735884031a3b9ddf7b1abecee0885ec61660588b1e7c6862bccf5116/chromadb-0.4.14-py3-none-any.whl.metadata\n","  Downloading chromadb-0.4.14-py3-none-any.whl.metadata (7.0 kB)\n","Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/site-packages (2.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/site-packages (from transformers) (0.17.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from transformers) (1.25.1)\n","Requirement already satisfied: packaging>=20.0 in /Users/francis/Library/Python/3.11/lib/python/site-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.11/site-packages (from transformers) (0.14.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/site-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/site-packages (from transformers) (4.65.0)\n","Requirement already satisfied: psutil in /Users/francis/Library/Python/3.11/lib/python/site-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/site-packages (from accelerate) (2.1.0)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/site-packages (from langchain) (2.0.21)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/site-packages (from langchain) (3.8.5)\n","Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.11/site-packages (from langchain) (3.7.1)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/site-packages (from langchain) (0.6.1)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/site-packages (from langchain) (1.33)\n","Requirement already satisfied: langsmith<0.1.0,>=0.0.43 in /usr/local/lib/python3.11/site-packages (from langchain) (0.0.43)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/site-packages (from langchain) (1.10.12)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/site-packages (from langchain) (8.2.3)\n","Collecting torch>=1.10.0 (from accelerate)\n","  Downloading torch-2.0.1-cp311-none-macosx_10_9_x86_64.whl (143.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.11/site-packages (from chromadb) (0.7.3)\n","Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/site-packages (from chromadb) (0.100.1)\n","Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.11/site-packages (from chromadb) (0.23.1)\n","Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/site-packages (from chromadb) (3.0.2)\n","Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.11/site-packages (from chromadb) (3.3.0)\n","Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/site-packages (from chromadb) (1.16.0)\n","Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/site-packages (from chromadb) (0.48.9)\n","Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/site-packages (from chromadb) (7.4.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/site-packages (from chromadb) (6.1.0)\n","Collecting grpcio>=1.58.0 (from chromadb)\n","  Obtaining dependency information for grpcio>=1.58.0 from https://files.pythonhosted.org/packages/bb/1c/4741e490b93488e077e36543b0acbfece41314b5a1ffae05bc7e2e9b3375/grpcio-1.59.0-cp311-cp311-macosx_10_10_universal2.whl.metadata\n","  Downloading grpcio-1.59.0-cp311-cp311-macosx_10_10_universal2.whl.metadata (4.0 kB)\n","Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/site-packages (from chromadb) (4.0.1)\n","Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/site-packages (from chromadb) (0.9.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/site-packages (from sentence_transformers) (0.16.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/site-packages (from sentence_transformers) (1.3.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/site-packages (from sentence_transformers) (1.11.3)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/site-packages (from sentence_transformers) (3.8.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/site-packages (from sentence_transformers) (0.1.99)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/site-packages (from anyio<4.0->langchain) (3.4)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/site-packages (from anyio<4.0->langchain) (1.3.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n","Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb) (0.27.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.2)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (4.23.4)\n","Requirement already satisfied: six>=1.5 in /Users/francis/Library/Python/3.11/lib/python/site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n","Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n","Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n","Requirement already satisfied: python-dateutil>2.1 in /Users/francis/Library/Python/3.11/lib/python/site-packages (from posthog>=2.4.0->chromadb) (2.8.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/site-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.1.6)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n","Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.0)\n","Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n","Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.20.0)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/site-packages (from nltk->sentence_transformers) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n","INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n","Collecting torchvision (from sentence_transformers)\n","  Downloading torchvision-0.15.2-cp311-cp311-macosx_10_9_x86_64.whl (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/site-packages (from torchvision->sentence_transformers) (10.0.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain-0.0.311-py3-none-any.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading chromadb-0.4.14-py3-none-any.whl (448 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.1/448.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading grpcio-1.59.0-cp311-cp311-macosx_10_10_universal2.whl (9.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: xformers\n","  Building wheel for xformers (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for xformers: filename=xformers-0.0.22-cp311-cp311-macosx_13_0_x86_64.whl size=488062 sha256=0d82ae0672ad95804be0cf4aa3d021bd4e0c38754633e26333bdd3cc4c375825\n","  Stored in directory: /Users/francis/Library/Caches/pip/wheels/8d/74/37/1fb987a5d8bf22e2bacee7c397d33f5c4d7420d13c8be458c1\n","Successfully built xformers\n","\u001b[33mWARNING: Skipping /usr/local/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: bitsandbytes, grpcio, einops, torch, xformers, torchvision, langchain, accelerate, chromadb\n","  Attempting uninstall: torch\n","\u001b[33m    WARNING: Skipping /usr/local/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n","\u001b[0m    Found existing installation: torch 2.1.0\n","    Uninstalling torch-2.1.0:\n","      Successfully uninstalled torch-2.1.0\n","  Attempting uninstall: torchvision\n","\u001b[33m    WARNING: Skipping /usr/local/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n","\u001b[0m    Found existing installation: torchvision 0.16.0\n","    Uninstalling torchvision-0.16.0:\n","      Successfully uninstalled torchvision-0.16.0\n","  Attempting uninstall: langchain\n","\u001b[33m    WARNING: Skipping /usr/local/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n","\u001b[0m    Found existing installation: langchain 0.0.310\n","    Uninstalling langchain-0.0.310:\n","      Successfully uninstalled langchain-0.0.310\n","  Attempting uninstall: chromadb\n","\u001b[33m    WARNING: Skipping /usr/local/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n","\u001b[0m    Found existing installation: chromadb 0.4.13\n","    Uninstalling chromadb-0.4.13:\n","      Successfully uninstalled chromadb-0.4.13\n","\u001b[33mWARNING: Skipping /usr/local/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping /usr/local/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping /usr/local/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping /usr/local/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping /usr/local/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping /usr/local/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping /usr/local/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping /usr/local/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping /usr/local/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n","\u001b[0mSuccessfully installed accelerate-0.23.0 bitsandbytes-0.41.1 chromadb-0.4.14 einops-0.7.0 grpcio-1.59.0 langchain-0.0.311 torch-2.0.1 torchvision-0.15.2 xformers-0.0.22\n","\u001b[33mWARNING: Skipping /usr/local/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping /usr/local/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping /usr/local/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install -U transformers accelerate einops langchain xformers bitsandbytes chromadb sentence_transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-09-24T11:30:52.671539Z","iopub.status.busy":"2023-09-24T11:30:52.671176Z","iopub.status.idle":"2023-09-24T11:31:02.57404Z","shell.execute_reply":"2023-09-24T11:31:02.572932Z","shell.execute_reply.started":"2023-09-24T11:30:52.671499Z"},"trusted":true},"outputs":[],"source":["from torch import cuda, bfloat16\n","import torch\n","import transformers\n","from transformers import AutoTokenizer\n","from time import time\n","import chromadb\n","from chromadb.config import Settings\n","from langchain.llms import HuggingFacePipeline\n","from langchain.document_loaders import TextLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.chains import RetrievalQA\n","from langchain.vectorstores import Chroma\n"]},{"cell_type":"markdown","metadata":{},"source":["# Initialize model, tokenizer, query pipeline"]},{"cell_type":"markdown","metadata":{},"source":["Define the model, the device, and the `bitsandbytes` configuration."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-09-24T11:31:02.576071Z","iopub.status.busy":"2023-09-24T11:31:02.575426Z","iopub.status.idle":"2023-09-24T11:31:02.709912Z","shell.execute_reply":"2023-09-24T11:31:02.708905Z","shell.execute_reply.started":"2023-09-24T11:31:02.57603Z"},"trusted":true},"outputs":[],"source":["model_id = '/kaggle/input/llama-2/pytorch/7b-chat-hf/1'\n","\n","device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n","\n","# set quantization configuration to load large model with less GPU memory\n","# this requires the `bitsandbytes` library\n","bnb_config = transformers.BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type='nf4',\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_compute_dtype=bfloat16\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Prepare the model and the tokenizer."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-09-24T11:31:02.713231Z","iopub.status.busy":"2023-09-24T11:31:02.712874Z","iopub.status.idle":"2023-09-24T11:34:25.391533Z","shell.execute_reply":"2023-09-24T11:34:25.390606Z","shell.execute_reply.started":"2023-09-24T11:31:02.713195Z"},"trusted":true},"outputs":[],"source":["time_1 = time()\n","model_config = transformers.AutoConfig.from_pretrained(\n","    model_id,\n",")\n","model = transformers.AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    trust_remote_code=True,\n","    config=model_config,\n","    quantization_config=bnb_config,\n","    device_map='auto',\n",")\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","time_2 = time()\n","print(f\"Prepare model, tokenizer: {round(time_2-time_1, 3)} sec.\")"]},{"cell_type":"markdown","metadata":{},"source":["Define the query pipeline."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-09-24T11:34:25.393544Z","iopub.status.busy":"2023-09-24T11:34:25.393127Z","iopub.status.idle":"2023-09-24T11:34:27.946285Z","shell.execute_reply":"2023-09-24T11:34:27.945304Z","shell.execute_reply.started":"2023-09-24T11:34:25.393507Z"},"trusted":true},"outputs":[],"source":["time_1 = time()\n","query_pipeline = transformers.pipeline(\n","        \"text-generation\",\n","        model=model,\n","        tokenizer=tokenizer,\n","        torch_dtype=torch.float16,\n","        device_map=\"auto\",)\n","time_2 = time()\n","print(f\"Prepare pipeline: {round(time_2-time_1, 3)} sec.\")"]},{"cell_type":"markdown","metadata":{},"source":["We define a function for testing the pipeline."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-09-24T11:34:27.950939Z","iopub.status.busy":"2023-09-24T11:34:27.950559Z","iopub.status.idle":"2023-09-24T11:34:27.960805Z","shell.execute_reply":"2023-09-24T11:34:27.958917Z","shell.execute_reply.started":"2023-09-24T11:34:27.9509Z"},"trusted":true},"outputs":[],"source":["def test_model(tokenizer, pipeline, prompt_to_test):\n","    \"\"\"\n","    Perform a query\n","    print the result\n","    Args:\n","        tokenizer: the tokenizer\n","        pipeline: the pipeline\n","        prompt_to_test: the prompt\n","    Returns\n","        None\n","    \"\"\"\n","    # adapted from https://huggingface.co/blog/llama2#using-transformers\n","    time_1 = time()\n","    sequences = pipeline(\n","        prompt_to_test,\n","        do_sample=True,\n","        top_k=10,\n","        num_return_sequences=1,\n","        eos_token_id=tokenizer.eos_token_id,\n","        max_length=200,)\n","    time_2 = time()\n","    print(f\"Test inference: {round(time_2-time_1, 3)} sec.\")\n","    for seq in sequences:\n","        print(f\"Result: {seq['generated_text']}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Test the query pipeline\n","\n","We test the pipeline with a query about the meaning of State of the Union (SOTU)."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-09-24T11:34:27.965217Z","iopub.status.busy":"2023-09-24T11:34:27.964942Z","iopub.status.idle":"2023-09-24T11:34:40.274764Z","shell.execute_reply":"2023-09-24T11:34:40.273475Z","shell.execute_reply.started":"2023-09-24T11:34:27.965192Z"},"trusted":true},"outputs":[],"source":["test_model(tokenizer,\n","           query_pipeline,\n","           \"Please explain what is the State of the Union address. Give just a definition. Keep it in 100 words.\")"]},{"cell_type":"markdown","metadata":{},"source":["# Retrieval Augmented Generation"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-09-23T19:22:16.434937Z","iopub.status.busy":"2023-09-23T19:22:16.433666Z","iopub.status.idle":"2023-09-23T19:22:16.440864Z","shell.execute_reply":"2023-09-23T19:22:16.439217Z","shell.execute_reply.started":"2023-09-23T19:22:16.434891Z"}},"source":["## Check the model with a HuggingFace pipeline\n","\n","\n","We check the model with a HF pipeline, using a query about the meaning of State of the Union (SOTU)."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-09-24T11:34:40.278384Z","iopub.status.busy":"2023-09-24T11:34:40.277537Z","iopub.status.idle":"2023-09-24T11:34:45.497736Z","shell.execute_reply":"2023-09-24T11:34:45.496602Z","shell.execute_reply.started":"2023-09-24T11:34:40.27833Z"},"trusted":true},"outputs":[],"source":["llm = HuggingFacePipeline(pipeline=query_pipeline)\n","# checking again that everything is working fine\n","llm(prompt=\"Please explain what is the State of the Union address. Give just a definition. Keep it in 100 words.\")"]},{"cell_type":"markdown","metadata":{},"source":["## Ingestion of data using Text loder\n","\n","We will ingest the newest presidential address, from Jan 2023."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-09-24T11:34:45.499774Z","iopub.status.busy":"2023-09-24T11:34:45.499156Z","iopub.status.idle":"2023-09-24T11:34:45.510252Z","shell.execute_reply":"2023-09-24T11:34:45.508979Z","shell.execute_reply.started":"2023-09-24T11:34:45.499734Z"},"trusted":true},"outputs":[],"source":["loader = TextLoader(\"/kaggle/input/president-bidens-state-of-the-union-2023/biden-sotu-2023-planned-official.txt\",\n","                    encoding=\"utf8\")\n","documents = loader.load()"]},{"cell_type":"markdown","metadata":{},"source":["## Split data in chunks\n","\n","We split data in chunks using a recursive character text splitter."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-09-24T11:34:45.512413Z","iopub.status.busy":"2023-09-24T11:34:45.511882Z","iopub.status.idle":"2023-09-24T11:34:45.543059Z","shell.execute_reply":"2023-09-24T11:34:45.542209Z","shell.execute_reply.started":"2023-09-24T11:34:45.512379Z"},"trusted":true},"outputs":[],"source":["text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n","all_splits = text_splitter.split_documents(documents)"]},{"cell_type":"markdown","metadata":{},"source":["## Creating Embeddings and Storing in Vector Store"]},{"cell_type":"markdown","metadata":{},"source":["Create the embeddings using Sentence Transformer and HuggingFace embeddings."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-09-24T11:34:45.544475Z","iopub.status.busy":"2023-09-24T11:34:45.544149Z","iopub.status.idle":"2023-09-24T11:34:53.204351Z","shell.execute_reply":"2023-09-24T11:34:53.203268Z","shell.execute_reply.started":"2023-09-24T11:34:45.544443Z"},"trusted":true},"outputs":[],"source":["model_name = \"sentence-transformers/all-mpnet-base-v2\"\n","model_kwargs = {\"device\": \"cuda\"}\n","\n","embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)"]},{"cell_type":"markdown","metadata":{},"source":["Initialize ChromaDB with the document splits, the embeddings defined previously and with the option to persist it locally."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-09-24T11:34:53.209668Z","iopub.status.busy":"2023-09-24T11:34:53.209241Z","iopub.status.idle":"2023-09-24T11:34:54.842076Z","shell.execute_reply":"2023-09-24T11:34:54.841118Z","shell.execute_reply.started":"2023-09-24T11:34:53.209635Z"},"trusted":true},"outputs":[],"source":["vectordb = Chroma.from_documents(documents=all_splits, embedding=embeddings, persist_directory=\"chroma_db\")"]},{"cell_type":"markdown","metadata":{},"source":["## Initialize chain"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-09-24T11:34:54.843922Z","iopub.status.busy":"2023-09-24T11:34:54.843557Z","iopub.status.idle":"2023-09-24T11:34:54.852247Z","shell.execute_reply":"2023-09-24T11:34:54.85108Z","shell.execute_reply.started":"2023-09-24T11:34:54.843887Z"},"trusted":true},"outputs":[],"source":["retriever = vectordb.as_retriever()\n","\n","qa = RetrievalQA.from_chain_type(\n","    llm=llm, \n","    chain_type=\"stuff\", \n","    retriever=retriever, \n","    verbose=True\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Test the Retrieval-Augmented Generation \n","\n","\n","We define a test function, that will run the query and time it."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-09-24T11:34:54.854961Z","iopub.status.busy":"2023-09-24T11:34:54.85463Z","iopub.status.idle":"2023-09-24T11:34:54.865233Z","shell.execute_reply":"2023-09-24T11:34:54.86406Z","shell.execute_reply.started":"2023-09-24T11:34:54.854935Z"},"trusted":true},"outputs":[],"source":["def test_rag(qa, query):\n","    print(f\"Query: {query}\\n\")\n","    time_1 = time()\n","    result = qa.run(query)\n","    time_2 = time()\n","    print(f\"Inference time: {round(time_2-time_1, 3)} sec.\")\n","    print(\"\\nResult: \", result)"]},{"cell_type":"markdown","metadata":{},"source":["Let's check few queries."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-09-24T11:34:54.867062Z","iopub.status.busy":"2023-09-24T11:34:54.866703Z","iopub.status.idle":"2023-09-24T11:35:10.254328Z","shell.execute_reply":"2023-09-24T11:35:10.253314Z","shell.execute_reply.started":"2023-09-24T11:34:54.867031Z"},"trusted":true},"outputs":[],"source":["query = \"What were the main topics in the State of the Union in 2023? Summarize. Keep it under 200 words.\"\n","test_rag(qa, query)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-09-24T11:35:10.256581Z","iopub.status.busy":"2023-09-24T11:35:10.255955Z","iopub.status.idle":"2023-09-24T11:35:24.62616Z","shell.execute_reply":"2023-09-24T11:35:24.625206Z","shell.execute_reply.started":"2023-09-24T11:35:10.256545Z"},"trusted":true},"outputs":[],"source":["query = \"What is the nation economic status? Summarize. Keep it under 200 words.\"\n","test_rag(qa, query)"]},{"cell_type":"markdown","metadata":{},"source":["## Document sources\n","\n","Let's check the documents sources, for the last query run."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-09-24T11:42:07.602359Z","iopub.status.busy":"2023-09-24T11:42:07.601993Z","iopub.status.idle":"2023-09-24T11:42:07.659413Z","shell.execute_reply":"2023-09-24T11:42:07.658367Z","shell.execute_reply.started":"2023-09-24T11:42:07.602331Z"},"trusted":true},"outputs":[],"source":["docs = vectordb.similarity_search(query)\n","print(f\"Query: {query}\")\n","print(f\"Retrieved documents: {len(docs)}\")\n","for doc in docs:\n","    doc_details = doc.to_json()['kwargs']\n","    print(\"Source: \", doc_details['metadata']['source'])\n","    print(\"Text: \", doc_details['page_content'], \"\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["# Conclusions\n","\n","\n","We used Langchain, ChromaDB and Llama 2 as a LLM to build a Retrieval Augmented Generation solution. For testing, we were using the latest State of the Union address from Jan 2023.\n","\n","\n","# More work on the same topic\n","\n","You can find more details about how to use a LLM with Kaggle. Few interesting topics are treated in:  \n","\n","* https://www.kaggle.com/code/gpreda/test-llama-2-quantized-with-llama-cpp (quantizing LLama 2 model using llama.cpp)\n","* https://www.kaggle.com/code/gpreda/fast-test-of-llama-v2-pre-quantized-with-llama-cpp  (quantized Llamam 2 model using llama.cpp)  \n","* https://www.kaggle.com/code/gpreda/test-of-llama-2-quantized-with-llama-cpp-on-cpu (quantized model using llama.cpp - running on CPU)\n"]},{"cell_type":"markdown","metadata":{},"source":["# References  \n","\n","[1] Murtuza Kazmi, Using LLaMA 2.0, FAISS and LangChain for Question-Answering on Your Own Data, https://medium.com/@murtuza753/using-llama-2-0-faiss-and-langchain-for-question-answering-on-your-own-data-682241488476  \n","\n","[2] Patrick Lewis, Ethan Perez, et. al., Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks, https://browse.arxiv.org/pdf/2005.11401.pdf \n","\n","[3] Minhajul Hoque, Retrieval Augmented Generation: Grounding AI Responses in Factual Data, https://medium.com/@minh.hoque/retrieval-augmented-generation-grounding-ai-responses-in-factual-data-b7855c059322  \n","\n","[4] Fangrui Liu\t, Discover the Performance Gain with Retrieval Augmented Generation, https://thenewstack.io/discover-the-performance-gain-with-retrieval-augmented-generation/\n","\n","[5] Andrew, How to use Retrieval-Augmented Generation (RAG) with Llama 2, https://agi-sphere.com/retrieval-augmented-generation-llama2/   \n","\n","[6] Yogendra Sisodia, Retrieval Augmented Generation Using Llama2 And Falcon, https://medium.com/@scholarly360/retrieval-augmented-generation-using-llama2-and-falcon-ed26c7b14670"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
